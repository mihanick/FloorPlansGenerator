{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "FloorPlanGenerator.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "olGtkW6oGeqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as tt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PJtJ_GlGeq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://mathieu.delalandre.free.fr/projects/sesyd/symbols/floorplans.html\n",
        "!wget -nc http://mathieu.delalandre.free.fr/projects/sesyd/symbols/floorplans/floorplans16-01.zip\n",
        "!unzip -q -o -d data/ floorplans16-01.zip\n",
        "\n",
        "DATA_DIR = 'data/'\n",
        "print(os.listdir(DATA_DIR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfiCAEpzGerB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 64\n",
        "batch_size = 128\n",
        "#stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
        "stats = (1, 1, 1), (1, 1, 1)\n",
        "\n",
        "transform = tt.Compose([\n",
        "    tt.Grayscale(num_output_channels=1),\n",
        "    tt.Resize(image_size),\n",
        "    tt.CenterCrop(image_size),\n",
        "    tt.ToTensor(),\n",
        "    #tt.Normalize(*stats),\n",
        "])\n",
        "\n",
        "train_ds = ImageFolder(DATA_DIR, transform = transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v75fuM-2GerI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 0, pin_memory = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK0it9InGerP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def denorm(img_tensors):\n",
        "#    return img_tensors * stats[1][0] + stats[0][0]\n",
        "\n",
        "def show_images(images, nmax = 16):\n",
        "    fig, ax = plt.subplots(figsize = (16,16))\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    denrom_batch = images.detach()[:nmax]\n",
        "    grid = make_grid(denrom_batch, nrow = 4).permute(1,2,0)\n",
        "    # print(torch.max(grid))\n",
        "    ad = (grid*255).byte()\n",
        "    ax.imshow(ad)\n",
        "\n",
        "def show_batch(dl, nmax = 16)    :\n",
        "    for images, _ in dl:\n",
        "        show_images(images, nmax)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVsUal71GerX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_batch(train_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74jvQl5AGerg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking = True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device  = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "    \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9BJnXY_Gern",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7SnX5AAGeru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrsSLreUGer0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_kernel = image_size // 64\n",
        "first_stride = first_kernel * 2\n",
        "first_padding = first_kernel // 4\n",
        "discriminator = nn.Sequential(\n",
        "    #in: 3x64x64\n",
        "    nn.Conv2d(1, 64, kernel_size = first_kernel, stride = first_stride, padding = first_padding, bias = False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.1, inplace = True),\n",
        "    #out: 64x32x32\n",
        "    \n",
        "    nn.Conv2d(64, 128, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.1, inplace = True),\n",
        "    #out: 128x16x16\n",
        "    \n",
        "    nn.Conv2d(128, 256, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.1, inplace = True),\n",
        "    #out: 256x8x8\n",
        "    \n",
        "    nn.Conv2d(256, 512, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.1, inplace = True),\n",
        "    #out: 512x4x4\n",
        "    \n",
        "    nn.Conv2d(512, 1, kernel_size = 4, stride = 1, padding = 0, bias = False),\n",
        "    \n",
        "    #out: 1x1x1\n",
        "    \n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "discriminator = to_device(discriminator,device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baJ7YDgYKjoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test output shape of discriminator\n",
        "print (first_kernel, first_stride, first_padding)\n",
        "for real_images, _ in tqdm(train_dl):\n",
        "    print (real_images.shape)\n",
        "    d = discriminator(to_device(real_images,device))\n",
        "    print(d.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X828zFFKGer8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_size = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMnjMWT-GesD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "num_layers =  int(math.log(image_size / 8,2))\n",
        "print(num_layers)\n",
        "startsize = int(64*2**num_layers)\n",
        "generator = nn.Sequential(\n",
        "    #in: latent_size x 1 x 1\n",
        "    nn.ConvTranspose2d(latent_size, startsize, kernel_size = 4, stride = 1, padding = 0, bias = False),\n",
        "    nn.BatchNorm2d(startsize),\n",
        "    nn.ReLU(True)\n",
        "    )\n",
        "a=startsize\n",
        "\n",
        "for i in reversed(range(num_layers)):\n",
        "    b = a // 2\n",
        "    generator.add_module(\"convtranspose2d\"+str(i), nn.ConvTranspose2d(a,b,kernel_size=4, stride=2, padding=1,bias=False))\n",
        "    generator.add_module(\"batchnorm\"+str(i),nn.BatchNorm2d(b))\n",
        "    generator.add_module(\"relu\"+str(i),nn.ReLU(True))\n",
        "    a //= 2\n",
        "\n",
        "generator.add_module(\"lastconv\",nn.ConvTranspose2d(64, 1, kernel_size= 4, stride= 2, padding= 1, output_padding= 0, bias = False))\n",
        "generator.add_module(\"tanh\",nn.Tanh())\n",
        "\n",
        "generator = to_device(generator, device)\n",
        "print(generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y70iDfcio51_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent = torch.randn(batch_size, latent_size, 1, 1, device = device)\n",
        "fake_images = generator(latent)\n",
        "print(fake_images.shape, torch.max(fake_images))\n",
        "show_images(fake_images.cpu())\n",
        "\n",
        "fake_preds = discriminator(fake_images)\n",
        "print(fake_preds.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfuOtjJbGesV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_discriminator(real_images, opt_d):\n",
        "    # clear grad\n",
        "    opt_d.zero_grad()\n",
        "    \n",
        "    # pass real images through discriminator\n",
        "    real_preds = discriminator(real_images)\n",
        "    real_targets = torch.ones(real_images.size(0), 1, device = device)\n",
        "\n",
        "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
        "    real_score = torch.mean(real_preds).item()\n",
        "    \n",
        "    # generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device = device)\n",
        "    fake_images = generator(latent)\n",
        "    \n",
        "    # pass fake images through discriminator\n",
        "    fake_targetes = torch.zeros(fake_images.size(0), 1, device = device)\n",
        "    fake_preds = discriminator(fake_images)\n",
        "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targetes)\n",
        "    fake_score = torch.mean(fake_preds).item()\n",
        "    \n",
        "    # update discriminator weights\n",
        "    loss = real_loss + fake_loss\n",
        "    loss.backward()\n",
        "    opt_d.step()\n",
        "    \n",
        "    return loss.item(), real_score, fake_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V7IGqxrGesY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_generator(opt_g):\n",
        "    # clear generator gradients\n",
        "    opt_g.zero_grad()\n",
        "    \n",
        "    # generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device = device)\n",
        "    fake_images = generator(latent)\n",
        "    \n",
        "    # try to fool the discriminator\n",
        "    preds = discriminator(fake_images)\n",
        "    targets = torch.ones(batch_size, 1, device = device)\n",
        "    loss = F.binary_cross_entropy(preds, targets)\n",
        "    \n",
        "    # update generator weights\n",
        "    loss.backward()\n",
        "    opt_g.step()\n",
        "    \n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiQFcISxGesb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_dir = 'generated'\n",
        "os.makedirs(sample_dir, exist_ok = True)\n",
        "\n",
        "def save_samples(index, latent_tensors, show= False):\n",
        "    fake_images = generator(latent_tensors).cpu()\n",
        "    fake_filename = 'generated-{0:0=4d}.png'.format(index)\n",
        "    # print(fake_images.shape, torch.max(fake_images))\n",
        "    \n",
        "    filename = os.path.join(sample_dir, fake_filename)\n",
        "    save_image(fake_images, filename, nrow = 4)\n",
        "    # print(\"Saving \", fake_filename)\n",
        "    if show:\n",
        "        show_images(fake_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYU2EHIyGesg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fixed_latent = torch.randn(image_size, latent_size, 1, 1, device = device)\n",
        "#save_samples(0, fixed_latent,  True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwQ4an7NGesn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, lr, start_idx = 1):\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # losses and scores\n",
        "    losses_g = []\n",
        "    losses_d = []\n",
        "    real_scores = []\n",
        "    fake_scores = []\n",
        "    \n",
        "    # create oprimizeres\n",
        "    opt_d = torch.optim.Adam(discriminator.parameters(), lr = lr/10, weight_decay=0.89, betas = (0.5, 0.999))\n",
        "    opt_g = torch.optim.Adam(generator.parameters(), lr = lr, weight_decay=0.99,  betas = (0.5, 0.999))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for real_images, _ in tqdm(train_dl):\n",
        "            # train discriminator\n",
        "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
        "            \n",
        "            # train generator\n",
        "            loss_g =  train_generator(opt_g)\n",
        "            \n",
        "            # record losses and scores\n",
        "            \n",
        "            losses_g.append(loss_g)\n",
        "            losses_d.append(loss_d)\n",
        "            real_scores.append(real_score)\n",
        "            fake_scores.append(fake_score)\n",
        "            \n",
        "            # pring losses and scores\n",
        "            message_template = \"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\"\n",
        "            print(message_template.format(\n",
        "                epoch + 1,\n",
        "                epochs,\n",
        "                loss_g,\n",
        "                loss_d,\n",
        "                real_score,\n",
        "                fake_score\n",
        "            ))\n",
        "            \n",
        "            save_samples(epoch+start_idx, fixed_latent, show = False)\n",
        "            \n",
        "    return losses_g, losses_d, real_scores, fake_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtEHMknKGesq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 5e-6\n",
        "epochs = 111\n",
        "\n",
        "history = fit(epochs, lr)\n",
        "losses_g, losses_d, real_scores, fake_scores = history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcBj5xnTGess",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(os.listdir('generated/'))\n",
        "from IPython.display import Image\n",
        "Image('generated/generated-{:04d}.png'.format(epochs))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbRwBONfGesv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(losses_d, '-')\n",
        "plt.plot(losses_g, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Discriminator', 'Generator'])\n",
        "plt.title('Losses')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FkRhHScGes1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(real_scores, '-')\n",
        "plt.plot(fake_scores, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('score')\n",
        "plt.legend(['Real', 'Fake'])\n",
        "plt.title('Scores')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKnVcxOKGes6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}